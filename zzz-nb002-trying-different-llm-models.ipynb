{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd35694-5f5a-4d16-8669-ec1f5bf43393",
   "metadata": {},
   "source": [
    "# Connect with alternative LLMs\n",
    "* Talk with Open Source LLMs like Llama3 and Mixtral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4312ba1-de37-450b-89a3-c0b21d955801",
   "metadata": {},
   "source": [
    "## Caveat\n",
    "* Keep in mind that the quality of Llama3 and Mixtral is still below the quality of OpenAI's ChatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7a6bc5-c149-4ef3-a6a7-71fbd72e098a",
   "metadata": {},
   "source": [
    "## Setup\n",
    "#### After you download the code from the github repository in your computer\n",
    "In terminal:\n",
    "* cd project_name\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell\n",
    "\n",
    "#### To open the notebook with Jupyter Notebooks\n",
    "In terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Go to the folder of notebooks and open the right notebook.\n",
    "\n",
    "#### To see the code in Virtual Studio Code or your editor of choice.\n",
    "* open Virtual Studio Code or your editor of choice.\n",
    "* open the project-folder\n",
    "* open the 002-trying-different-llm-models.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba604a0-5ce9-42b1-92d8-ca8e27e7232b",
   "metadata": {},
   "source": [
    "## Create your .env file\n",
    "* In the github repo we have included a file named .env.example\n",
    "* Rename that file to .env file and here is where you will add your confidential api keys. Remember to include:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d072f-291b-42f3-81ee-bf2c779b2870",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **002-trying-different-llm-models**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5961599-9738-454f-81ad-bb0784f180b4",
   "metadata": {},
   "source": [
    "## Track operations\n",
    "From now on, we can track the operations **and the cost** of this project from LangSmith:\n",
    "* [smith.langchain.com](https://smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398411fd-07b6-4882-9625-e87ec3751da2",
   "metadata": {},
   "source": [
    "## Intro to Groq\n",
    "* Groq is an AI Startup company. **It is not the same as Grok, the LLM from Elon Musk**.\n",
    "* It has developed a new chip call LPU (Language Processing Unit) which is specificly design to run LLMs faster and cheaper.\n",
    "* It offers a Groq Cloud where you can try Open Source LLMs like Llama3 or Mixtral.\n",
    "* **It allows you to use Llama3 or Mixtral in your apps for free using a Groq API Key with some Rate Limits**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06a1309-a5f5-4797-aab2-e90d77c2dde5",
   "metadata": {},
   "source": [
    "## How to get a free Groq API Key\n",
    "* Login into Groq Cloud: [https://console.groq.com/login](https://console.groq.com/login)\n",
    "* Once logged in, click on API Keys (left sidebar).\n",
    "* Create a new API Key.\n",
    "* Copy the API Key and paste it in your .env file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c154f-c329-4148-a57d-ed18fcd05d32",
   "metadata": {},
   "source": [
    "## How to install Groq in your project\n",
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you.\n",
    "\n",
    "LangChain has a module for it. We can install it the same way we install other LangChain modules, using PIP or (if we are working in a Poetry app) we can also install it using Poetry. Use one of the following options:\n",
    "* pip install langchain-groq\n",
    "* poetry add langchain-groq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819fad70-2d71-4e4a-b8a6-20285d7eb44f",
   "metadata": {},
   "source": [
    "## How to use Groq in your LangChain or CrewAI project\n",
    "Very easy. Just add the following line at the top of your file:\n",
    "* from langchain_groq import ChatGroq\n",
    "\n",
    "And then, in the code, if you want to use Llama3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce029dd-1e8b-4b82-98f6-bf9bfd09ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "     model=\"llama3-70b-8192\"\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3f9434-fb9f-4960-af68-55af2d86d847",
   "metadata": {},
   "source": [
    "Or if you want to use Mixtral:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2232591-6853-4840-b9d4-4b338a8d81d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatGroq(\n",
    "#     model=\"mixtral-8x7b-32768\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583dcd83-520b-4dc2-a160-1578314a847e",
   "metadata": {},
   "source": [
    "## You can take a look at Groq Rate limits here\n",
    "* https://console.groq.com/settings/limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4043b0-6f4e-4834-ac5c-8f3c1427c89d",
   "metadata": {},
   "source": [
    "## Groq pricing for projects in Production\n",
    "* [Groq pricing](https://wow.groq.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e299ed0-391d-4578-aee6-2537ce294252",
   "metadata": {},
   "source": [
    "## Let's give it a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f6a62-115f-4d26-8809-2e604bddd82e",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e93ed82f-d41b-4608-83d1-1053573905ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0548e514-cf7a-4f53-8df4-b6c3d03dc696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "groq_api_key = os.environ[\"GROQ_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3e7309f-3080-4bd0-af0f-374cc642b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llamaChatModel = ChatGroq(\n",
    "    model=\"llama3-70b-8192\", \n",
    "    api_key= groq_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8527fb7a-69a1-44ab-9601-e3e259df642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistralChatModel = ChatGroq(\n",
    "    model=\"mixtral-8x7b-32768\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f41aad1b-4aba-4bf4-a06d-2925a68b4828",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are an expert about Roman history. I will ask you some questions about it.\"),\n",
    "    (\"human\", \"Who where the first kings of Rome?\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba27bc49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df753975-ebd0-49d0-bd01-56bee372eb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to batch ingest runs: LangSmithError('Failed to POST https://api.smith.langchain.com/runs/batch in LangSmith API. HTTPError(\\'403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/batch\\', \\'{\"detail\":\"Forbidden\"}\\')')\n"
     ]
    }
   ],
   "source": [
    "llamaResponse = llamaChatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "850e5967-ea3a-434a-8aed-406f29ed89aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to Roman tradition, the first king of Rome was Romulus, who is said to have founded the city in 753 BCE. However, the historical record is a bit more complex.\n",
      "\n",
      "The traditional account, as recorded by the Roman historian Livy, holds that Romulus was the first king of Rome, ruling from 753 to 716 BCE. He was followed by six other kings, known as the \"Seven Kings of Rome.\" These kings were:\n",
      "\n",
      "1. Romulus (753-716 BCE)\n",
      "2. Numa Pompilius (716-673 BCE)\n",
      "3. Tullus Hostilius (673-642 BCE)\n",
      "4. Ancus Marcius (642-617 BCE)\n",
      "5. Lucius Tarquinius Priscus (617-579 BCE)\n",
      "6. Servius Tullius (579-534 BCE)\n",
      "7. Lucius Tarquinius Superbus (534-510 BCE)\n",
      "\n",
      "These kings are said to have ruled Rome during its early years, establishing the city's institutions, laws, and customs. However, it's worth noting that the historicity of these early kings is subject to debate among historians, and some scholars believe that they may be semi-legendary figures.\n",
      "\n",
      "Despite these uncertainties, the tradition of the Seven Kings of Rome has had a profound impact on Roman history and culture, shaping the city's identity and informing its later development.\n"
     ]
    }
   ],
   "source": [
    "print(llamaResponse.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63ce3b58-09d0-431b-95d2-ce9c2fbb5a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistralResponse = mistralChatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f5dc68-4e8d-4006-9354-5d290901b77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an assistant, I can provide you with the following information about tragic deaths in the Kennedy family:\n",
      "\n",
      "1. Joseph P. Kennedy Sr.'s son, Joseph P. Kennedy Jr., died in 1944 during World War II when his plane exploded during a secret mission.\n",
      "\n",
      "2. John F. Kennedy, the 35th President of the United States, was assassinated in Dallas, Texas, on November 22, 1963.\n",
      "\n",
      "3. Robert F. Kennedy, a US Senator and Attorney General, was assassinated in Los Angeles, California, on June 5, 1968.\n",
      "\n",
      "4. John F. Kennedy Jr., the son of President John F. Kennedy, died in a plane crash off the coast of Martha's Vineyard, Massachusetts, on July 16, 1999. His wife Carolyn Bessette Kennedy and sister-in-law Lauren Bessette also died in the crash.\n",
      "\n",
      "5. Kathleen Cavendish, Marchioness of Hartington, was the sister of John F. Kennedy. She died in a plane crash in France on May 13, 1948.\n",
      "\n",
      "6. Michael LeMoyne Kennedy, a son of Robert F. Kennedy, died in a skiing accident in Aspen, Colorado, on December 31, 1997.\n",
      "\n",
      "These are some of the most notable tragic deaths in the Kennedy family. There have been other deaths and accidents involving Kennedy family members, but these are the ones that have had the most significant impact on American history and politics.\n"
     ]
    }
   ],
   "source": [
    "print(mistralResponse.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c70e41d-5a7a-4831-a1be-978ccaceda07",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 002-trying-different-llm-models.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 002-trying-different-llm-models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47d77fd-c1ee-4e13-9219-7b5d16069f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
